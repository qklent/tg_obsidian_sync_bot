# Obsidian Telegram Sync Bot — Architecture

## Problem

Obsidian is used across 4 devices (Mac, Ubuntu, 2x Android) synced via obsidian-git plugin. Opening Obsidian just to jot a quick note is slow. Quick notes and forwarded Telegram posts end up in "Saved Messages" and are never revisited. The bot solves this by accepting messages in Telegram and pushing them as properly categorized markdown files to the Obsidian git repo.

## High-level flow

```
User sends message to Telegram bot
       │
       ▼
Bot receives message (text / forward / photo / document / voice / link)
       │
       ▼
Parse & normalize: extract text, captions, download media
       │
       ▼
LLM call (OpenRouter, lightweight model)
  Input:  message content + vault folder tree with descriptions + tag list
  Output: { folder, filename, tags, formatted_markdown }
       │
       ▼
Write .md file into local clone of Obsidian vault
       │
       ▼
git add → commit → push  (debounced, batched per 30s window)
       │
       ▼
Obsidian git plugin pulls on all devices
```

## Vault details

- **Git repo:** github.com/qklent/obsidian_notes.git
- **Vault root (notes):** the repo root itself
- **Attachments folder:** `images/`
- **Current folder structure:**

```
ege/                        — ЕГЭ prep materials
eng/                        — English learning (grammar, vocab, homework)
  behave/                   — English behavioral interview practice
headaches/                  — Headache diary
inference optimization/     — ML inference optimization notes
interview/                  — Job interview prep
quant/                      — Quantitative finance
speech_therapy/             — Speech therapy exercises
uni/                        — University coursework
  oup/                      — University: OUP course
  philosophy/               — University: philosophy
  tayak/                    — University: TAYAK course (lectures, exam)
вкр/                        — Bachelor thesis (ВКР)
  Voice conversion/         — Main thesis topic
    reference_papers/       — Papers to read
```

## Tech stack

| Component        | Choice                          | Reason                                           |
| ---------------- | ------------------------------- | ------------------------------------------------ |
| Language         | Python 3.12                     | Best Telegram bot ecosystem                      |
| Telegram         | aiogram 3.x                     | Async, modern, handles all message types         |
| LLM              | OpenRouter via `openai` SDK     | openai SDK works with any OpenAI-compatible API  |
| Git              | subprocess (plain git CLI)      | Simple, no extra dependency, reliable            |
| Config           | YAML                            | Human-editable vault structure + descriptions    |
| Template         | Jinja2                          | Note markdown rendering                          |
| Containerization | Docker + docker-compose         | Reproducible deployment on VPS                   |
| No database      | —                               | All state lives in Obsidian vault files + git    |

No SQLite. No external database. GTD and all metadata are Obsidian frontmatter tags — managed directly in Obsidian, not via Telegram.

## Project structure

```
tg_obsidian_sync/
├── bot/
│   ├── __init__.py
│   ├── main.py                 # Entrypoint: init aiogram, register handlers
│   ├── config.py               # Load settings + vault_structure.yaml
│   ├── handlers.py             # Telegram message handlers
│   ├── llm.py                  # OpenRouter calls, prompt building
│   ├── git_sync.py             # git add/commit/push with debounce
│   ├── vault.py                # Write .md files, manage attachments
│   └── note_template.md.j2    # Jinja2 template for notes
├── config/
│   ├── settings.yaml           # Bot configuration
│   └── vault_structure.yaml    # Folder tree + descriptions for LLM
├── Dockerfile
├── docker-compose.yaml
├── requirements.txt
└── architecture.md             # This file
```

## Configuration

### settings.yaml

```yaml
telegram:
  bot_token: "${TG_BOT_TOKEN}"       # resolved from env
  allowed_user_ids: [123456789]       # only you

openrouter:
  api_key: "${OPENROUTER_API_KEY}"    # resolved from env
  model: "google/gemini-2.0-flash-001"

vault:
  repo_path: "/vault"                 # mount point inside container
  attachments_dir: "images"

git:
  commit_debounce_seconds: 30         # batch commits within this window
```

### vault_structure.yaml

This file describes the vault folder tree and is fed to the LLM as context for classification. Each folder has a `description` field — a short text explaining what goes there.

```yaml
# Descriptions can be auto-generated by LLM based on folder content.
# See "Future: auto-updating descriptions" section below.

folders:
  - path: "ege"
    description: "ЕГЭ exam preparation materials and review notes"
  - path: "eng"
    description: "English learning: grammar rules, vocabulary, homework, essays"
    children:
      - path: "eng/behave"
        description: "Behavioral interview answers and practice in English"
  - path: "headaches"
    description: "Headache diary and health tracking"
  - path: "inference optimization"
    description: "ML model inference optimization techniques (CPU, GPU, quantization)"
  - path: "interview"
    description: "Job interview preparation: questions, company-specific notes, practice"
  - path: "quant"
    description: "Quantitative finance: books, strategies, notes"
  - path: "speech_therapy"
    description: "Speech therapy exercises and progress"
  - path: "uni"
    description: "University coursework and deadlines"
    children:
      - path: "uni/oup"
        description: "OUP course materials"
      - path: "uni/philosophy"
        description: "Philosophy course notes and seminar prep"
      - path: "uni/tayak"
        description: "TAYAK course: lectures and exam prep"
  - path: "вкр"
    description: "Bachelor thesis (ВКР) on voice conversion"
    children:
      - path: "вкр/Voice conversion"
        description: "Main thesis work: architecture, experiments, ideas, data, requirements"
        children:
          - path: "вкр/Voice conversion/reference_papers"
            description: "Academic papers and reading list for thesis"
  - path: "inbox"
    description: "Default fallback. Anything that doesn't clearly fit elsewhere."

tags:
  - toread
  - audio_processing
  - ai_agent
  - experiment
  - idea
  - deadline
  - reference
  - voice_conversion
  - ml
  - university
  - english
  - interview_prep
  - quick_note
```

## LLM integration

### Prompt

```
You are a note classifier for an Obsidian vault.

FOLDERS (with descriptions):
{yaml_dump_of_folders}

AVAILABLE TAGS:
{comma_separated_tags}

Given the user's message below, respond with ONLY valid JSON:
{
  "folder": "exact/folder/path from the list above",
  "filename": "short-kebab-case-name",
  "tags": ["tag1", "tag2"],
  "title": "Human readable title",
  "content": "cleaned up / formatted version of the message in markdown"
}

Rules:
- If the message doesn't fit any folder, use "inbox"
- filename must be filesystem-safe, kebab-case, max 60 chars
- Pick 1-4 tags that are most relevant
- content: preserve the original meaning, fix formatting, add markdown structure if appropriate
- If the message is a forwarded post or article, add a "source" line at the top of content
- Respond ONLY with the JSON object, no other text

USER MESSAGE:
{message_text}
```

Model: a cheap fast model from OpenRouter (Gemini 2.0 Flash, Mistral Small, etc). The task is simple structured extraction — no need for a large model.

### LLM call

Use the `openai` Python SDK with `base_url="https://openrouter.ai/api/v1"`. This is the simplest integration — no custom HTTP client needed.

## Message handling

### Supported message types

| Type              | Processing                                                       |
| ----------------- | ---------------------------------------------------------------- |
| Text              | Send directly to LLM                                            |
| Forwarded text    | Extract source (channel/user), prepend to text, send to LLM     |
| Photo             | Download to `images/`, send caption (or "photo with no caption") to LLM, embed `![[images/file.jpg]]` in note |
| Document/File     | Download to `images/`, mention in note                           |
| Link/URL          | Extract URL, send with surrounding text to LLM                  |
| Voice message     | Future: transcribe with Whisper. For now: save .ogg, tag `voice` |

### Handler logic (handlers.py)

1. Check `message.from_user.id` is in `allowed_user_ids` — ignore otherwise
2. Extract text content based on message type
3. If media: download file to vault attachments dir
4. Call LLM for classification
5. Render note from Jinja2 template
6. Write .md file to vault
7. Trigger git sync (debounced)
8. Reply with confirmation: "Saved to `folder/filename.md` with tags: #tag1 #tag2"

## Note template

```markdown
---
tags:
  {%- for tag in tags %}
  - {{ tag }}
  {%- endfor %}
source: telegram
created: {{ created }}
---

# {{ title }}

{{ content }}
```

## Git sync (git_sync.py)

### Debounced push

When multiple messages arrive in quick succession, we don't want a commit+push per message. Instead:

1. On each new file write, mark that a sync is needed
2. An async background task checks every N seconds (configurable, default 30)
3. If dirty: `git add -A && git commit -m "telegram: add N notes" && git push`
4. Use `asyncio.Lock` to prevent concurrent git operations

### Implementation

```python
class GitSync:
    def __init__(self, repo_path: str, debounce_seconds: int = 30):
        self.repo_path = repo_path
        self.debounce_seconds = debounce_seconds
        self._dirty = False
        self._lock = asyncio.Lock()

    def mark_dirty(self):
        self._dirty = True

    async def sync_loop(self):
        """Run as background task. Periodically commit+push if dirty."""
        while True:
            await asyncio.sleep(self.debounce_seconds)
            if self._dirty:
                async with self._lock:
                    self._dirty = False
                    await self._run_git()

    async def _run_git(self):
        # subprocess: git add -A && git commit && git push
        ...
```

## Docker setup

### Dockerfile

```dockerfile
FROM python:3.12-slim

RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY bot/ bot/
COPY config/ config/

CMD ["python", "-m", "bot.main"]
```

### docker-compose.yaml

```yaml
services:
  bot:
    build: .
    restart: unless-stopped
    env_file: .env
    volumes:
      - vault_repo:/vault          # persistent vault clone
      - ./config:/app/config       # editable config without rebuild
      - ssh_keys:/root/.ssh:ro     # git SSH keys for push
    environment:
      - TG_BOT_TOKEN
      - OPENROUTER_API_KEY

volumes:
  vault_repo:                       # persists the git clone
  ssh_keys:                         # mount host SSH keys
```

### Initial setup on VPS

```bash
# 1. Clone the vault repo into a docker volume or host dir
git clone git@github.com:qklent/obsidian_notes.git /path/to/vault

# 2. Configure .env
TG_BOT_TOKEN=...
OPENROUTER_API_KEY=...

# 3. Run
docker-compose up -d
```

## Security

- **allowed_user_ids**: Only specified Telegram user IDs can interact with the bot. All other messages are silently ignored.
- **Git auth**: Use SSH keys (mounted into container), NOT the PAT currently embedded in the remote URL. The current remote URL has an exposed PAT — this should be rotated and switched to SSH.
- **Secrets**: All tokens live in `.env`, never in config files or code.

## Future: auto-updating folder descriptions

The vault_structure.yaml descriptions should evolve as content changes. The planned approach:

1. **Trigger**: After every N notes added to a folder (or on a cron schedule)
2. **Process**: Read the last ~20 filenames + frontmatter from that folder → send to LLM → ask for an updated one-line description
3. **Output**: Overwrite the description in vault_structure.yaml
4. **New folders**: If LLM consistently suggests "inbox" for a pattern of notes, prompt the user (via Telegram) to create a new folder. Or auto-create after threshold.

This is NOT implemented in v1 — the architecture accommodates it by keeping descriptions in a separate YAML file that can be programmatically rewritten.

## Requirements

```
aiogram>=3.4,<4
openai>=1.0
pyyaml>=6.0
jinja2>=3.1
python-dotenv>=1.0
```

## Summary

The bot is a single Python async process:
- aiogram long-polling loop handles Telegram messages
- LLM (OpenRouter) classifies each message into folder + tags + formatted content
- Markdown file is written to the local vault clone
- Background task debounces git commits and pushes
- Obsidian-git plugin on all devices pulls automatically
- No database — all state is Obsidian markdown + git
- Runs in Docker on a 2CPU/8RAM VPS
